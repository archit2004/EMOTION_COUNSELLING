{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions.face_mesh_connections import FACEMESH_TESSELATION\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.sparse\n",
    "import pathlib, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path: c:\\Users\\Dell\\OneDrive - vit.ac.in\\Documents\\Projects\\Emotion_counselling\\Facial-Emotion-Classification-main2\\Facial-Emotion-Classification-main\\GNN\n",
      "\n",
      "Processing emotion: face_angry\n",
      "Found 7978 image files\n",
      "Processing 1/7978: 0.jpg\n",
      "Processing 2/7978: 1.jpg\n",
      "Processing 3/7978: 10.jpg\n",
      "Processing 4/7978: 10002.jpg\n",
      "Processing 5/7978: 10016.jpg\n",
      "Processing 6/7978: 10038.jpg\n",
      "Processing 7/7978: 10052.jpg\n",
      "Processing 8/7978: 10063.jpg\n",
      "Processing 9/7978: 10065.jpg\n",
      "Processing 10/7978: 10069.jpg\n",
      "Processing 101/7978: 10743.jpg\n",
      "Processing 201/7978: 1158.jpg\n",
      "Processing 301/7978: 12404.jpg\n",
      "Processing 401/7978: 13208.jpg\n",
      "Processing 501/7978: 13942.jpg\n",
      "Processing 601/7978: 14719.jpg\n",
      "Processing 701/7978: 15620.jpg\n",
      "Processing 801/7978: 16312.jpg\n",
      "Processing 901/7978: 17140.jpg\n",
      "Processing 1001/7978: 17856.jpg\n",
      "Processing 1101/7978: 18492.jpg\n",
      "Processing 1201/7978: 19067.jpg\n",
      "Processing 1301/7978: 19765.jpg\n",
      "Processing 1401/7978: 2067.jpg\n",
      "Processing 1501/7978: 21371.jpg\n",
      "Processing 1601/7978: 22177.jpg\n",
      "Processing 1701/7978: 23.jpg\n",
      "Processing 1801/7978: 23797.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 231\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_processed\u001b[38;5;241m/\u001b[39m(total_processed\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mtotal_errors)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 231\u001b[0m     \u001b[43mprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 198\u001b[0m, in \u001b[0;36mprocess_dataset\u001b[1;34m(verbose, show_progress)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_progress \u001b[38;5;129;01mand\u001b[39;00m (img_count \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m img_count \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(image_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 198\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_img\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m    201\u001b[0m     total_processed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[1], line 143\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(img_path, plot, verbose)\u001b[0m\n\u001b[0;32m    141\u001b[0m name \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(img_path)\u001b[38;5;241m.\u001b[39mstem\n\u001b[0;32m    142\u001b[0m adjacency_matrix \u001b[38;5;241m=\u001b[39m get_matrix_adj(graph)\n\u001b[1;32m--> 143\u001b[0m \u001b[43msave_adjacency_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjacency_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m save_meshpoints(mesh_points, img_path)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Plot if requested\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 103\u001b[0m, in \u001b[0;36msave_adjacency_matrix\u001b[1;34m(adjacency_matrix, filename)\u001b[0m\n\u001b[0;32m    100\u001b[0m path_name\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    102\u001b[0m file_out \u001b[38;5;241m=\u001b[39m path_name\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_npz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency_matrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_matrix_io.py:75\u001b[0m, in \u001b[0;36msave_npz\u001b[1;34m(file, matrix, compressed)\u001b[0m\n\u001b[0;32m     73\u001b[0m     arrays_dict\u001b[38;5;241m.\u001b[39mupdate(_is_array\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compressed:\n\u001b[1;32m---> 75\u001b[0m     np\u001b[38;5;241m.\u001b[39msavez_compressed(file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marrays_dict)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     np\u001b[38;5;241m.\u001b[39msavez(file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marrays_dict)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:710\u001b[0m, in \u001b[0;36msavez_compressed\u001b[1;34m(file, *args, **kwds)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_savez_compressed_dispatcher)\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msavez_compressed\u001b[39m(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m    649\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;124;03m    Save several arrays into a single file in compressed ``.npz`` format.\u001b[39;00m\n\u001b[0;32m    651\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[43m_savez\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:743\u001b[0m, in \u001b[0;36m_savez\u001b[1;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;66;03m# always force zip64, gh-10776\u001b[39;00m\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zipf\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, force_zip64\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m--> 743\u001b[0m         \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m zipf\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\format.py:735\u001b[0m, in \u001b[0;36mwrite_array\u001b[1;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mnditer(\n\u001b[0;32m    733\u001b[0m             array, flags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexternal_loop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffered\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzerosize_ok\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    734\u001b[0m             buffersize\u001b[38;5;241m=\u001b[39mbuffersize, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 735\u001b[0m         \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\zipfile.py:1128\u001b[0m, in \u001b[0;36m_ZipWriteFile.write\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_crc \u001b[38;5;241m=\u001b[39m crc32(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_crc)\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compressor:\n\u001b[1;32m-> 1128\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fileobj\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1, \n",
    "    refine_landmarks=False,  # Set to False to get 468 landmarks without iris\n",
    "    min_detection_confidence=0.5, \n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"\n",
    "    Process frame and extract facial landmarks\n",
    "    Returns None if no face is detected\n",
    "    \"\"\"\n",
    "    H, W, _ = frame.shape\n",
    "    rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results_mesh = face_mesh.process(rgb_image)\n",
    "    \n",
    "    # Check if face landmarks were detected\n",
    "    if not results_mesh.multi_face_landmarks:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Extract mesh points\n",
    "    mesh_points = np.array([\n",
    "        np.multiply([p.x, p.y], [W, H]).astype(int) \n",
    "        for p in results_mesh.multi_face_landmarks[0].landmark\n",
    "    ])\n",
    "    \n",
    "    # Calculate scale factor using nose tip and forehead\n",
    "    nose_tip = mesh_points[4]\n",
    "    forehead = mesh_points[151]\n",
    "    scale_factor = np.linalg.norm(forehead - nose_tip)\n",
    "    \n",
    "    if np.isclose(scale_factor, 0):\n",
    "        scale_factor = 1e-6\n",
    "        \n",
    "    return results_mesh, mesh_points, scale_factor\n",
    "\n",
    "def gera_grafos(results_mesh, mesh_points, scale_factor):\n",
    "    \"\"\"Generate graph from mesh points\"\"\"\n",
    "    graph = nx.Graph()\n",
    "    \n",
    "    # Add all nodes from mesh_points to the graph\n",
    "    for i in range(len(mesh_points)):\n",
    "        graph.add_node(i, pos=mesh_points[i])\n",
    "    \n",
    "    # Add edges based on MediaPipe face mesh connections\n",
    "    for connection in FACEMESH_TESSELATION:\n",
    "        graph.add_edge(connection[0], connection[1])\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def plot_graph(graph, mesh_points):\n",
    "    \"\"\"Plot the facial mesh graph\"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    pos_dict = {i: mesh_points[i] for i in range(len(mesh_points))}\n",
    "    nx.draw_networkx(\n",
    "        graph, \n",
    "        pos=pos_dict, \n",
    "        node_size=10, \n",
    "        node_color='black', \n",
    "        edge_color='gray', \n",
    "        with_labels=False,\n",
    "        width=0.5\n",
    "    )\n",
    "    # Flip the image upside down to match face orientation\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"Facial Mesh Graph\")\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "def get_matrix_adj(graph):\n",
    "    \"\"\"Get adjacency matrix from graph\"\"\"\n",
    "    matrix_adj = nx.adjacency_matrix(graph)\n",
    "    sparse_matrix = scipy.sparse.csr_matrix(matrix_adj)\n",
    "    return sparse_matrix\n",
    "\n",
    "def save_adjacency_matrix(adjacency_matrix, filename):\n",
    "    \"\"\"Save adjacency matrix to file\"\"\"\n",
    "    path_name = pathlib.Path(filename).parent.absolute()\n",
    "    emotion = path_name.name.split('_')[1]\n",
    "    path_name = path_name.parent.absolute()\n",
    "    path_name = path_name.joinpath(f'{emotion}_adj')\n",
    "    \n",
    "    filename = pathlib.Path(filename).absolute()\n",
    "    path_name.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    file_out = path_name.joinpath(f'{filename.stem}.npz')\n",
    "    scipy.sparse.save_npz(file_out, adjacency_matrix)\n",
    "\n",
    "def save_meshpoints(mesh_points, filename):\n",
    "    \"\"\"Save mesh points to JSON file\"\"\"\n",
    "    path_name = pathlib.Path(filename).parent.absolute()\n",
    "    emotion = path_name.name.split('_')[1]\n",
    "    path_name = path_name.parent.absolute()\n",
    "    path_name = path_name.joinpath(f'{emotion}_meshpoints')\n",
    "    \n",
    "    filename = pathlib.Path(filename).absolute()\n",
    "    path_name.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    file_out = path_name.joinpath(f'{filename.stem}.json')\n",
    "    with open(file_out, 'w') as outfile:\n",
    "        json.dump(mesh_points.tolist(), outfile)\n",
    "\n",
    "def pipeline(img_path, plot=False, verbose=False):\n",
    "    \"\"\"Main processing pipeline\"\"\"\n",
    "    try:\n",
    "        # Read image\n",
    "        frame = cv2.imread(img_path)\n",
    "        if frame is None:\n",
    "            if verbose:\n",
    "                print(f\"Could not read image: {img_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Preprocess frame\n",
    "        results_mesh, mesh_points, scale_factor = preprocess_frame(frame)\n",
    "        \n",
    "        if results_mesh is None:\n",
    "            if verbose:\n",
    "                print(f\"No face detected in: {img_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Generate graph\n",
    "        graph = gera_grafos(results_mesh, mesh_points, scale_factor)\n",
    "        \n",
    "        # Save data\n",
    "        name = pathlib.Path(img_path).stem\n",
    "        adjacency_matrix = get_matrix_adj(graph)\n",
    "        save_adjacency_matrix(adjacency_matrix, img_path)\n",
    "        save_meshpoints(mesh_points, img_path)\n",
    "        \n",
    "        # Plot if requested\n",
    "        if plot:\n",
    "            plot_graph(graph, mesh_points)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error processing {img_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def process_dataset(verbose=False, show_progress=True):\n",
    "    \"\"\"Process the entire dataset - ALL images in ALL emotion folders\"\"\"\n",
    "    print(\"Current path:\", pathlib.Path().absolute())\n",
    "    current_path = pathlib.Path().absolute()\n",
    "    parent_path = current_path.parent\n",
    "    \n",
    "    # Define emotion paths\n",
    "    emotion_folders = [\n",
    "        'face_angry', 'face_disgusted', 'face_happy', \n",
    "        'face_neutral', 'face_sad', 'face_surprised'\n",
    "    ]\n",
    "    \n",
    "    path_list = [parent_path / folder for folder in emotion_folders]\n",
    "    \n",
    "    total_processed = 0\n",
    "    total_errors = 0\n",
    "    \n",
    "    for emotion_path in path_list:\n",
    "        if not emotion_path.exists():\n",
    "            print(f\"Path does not exist: {emotion_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing emotion: {emotion_path.name}\")\n",
    "        \n",
    "        error_count = 0\n",
    "        img_count = 0\n",
    "        \n",
    "        try:\n",
    "            emotion_files = os.listdir(emotion_path)\n",
    "            image_files = [f for f in emotion_files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "            \n",
    "            print(f\"Found {len(image_files)} image files\")\n",
    "            \n",
    "            for img in image_files:\n",
    "                try:\n",
    "                    path_img = emotion_path / img\n",
    "                    \n",
    "                    # Show progress every 100 images (or based on show_progress)\n",
    "                    if show_progress and (img_count % 100 == 0 or img_count < 10):\n",
    "                        print(f\"Processing {img_count+1}/{len(image_files)}: {img}\")\n",
    "                    \n",
    "                    success = pipeline(str(path_img), plot=False, verbose=verbose)\n",
    "                    \n",
    "                    if success:\n",
    "                        total_processed += 1\n",
    "                        if verbose and img_count < 5:  # Only show first few if verbose\n",
    "                            print(f\"✅ Successfully processed: {img}\")\n",
    "                    else:\n",
    "                        error_count += 1\n",
    "                        total_errors += 1\n",
    "                        if verbose:\n",
    "                            print(f\"❌ Failed to process: {img}\")\n",
    "                    \n",
    "                    img_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if verbose:\n",
    "                        print(f\"❌ Error processing {img}: {str(e)}\")\n",
    "                    error_count += 1\n",
    "                    total_errors += 1\n",
    "                    continue\n",
    "            \n",
    "            print(f\"Completed {emotion_path.name}: {img_count} total, {error_count} errors\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing folder {emotion_path}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\n=== FINAL SUMMARY ===\")\n",
    "    print(f\"Total images processed successfully: {total_processed}\")\n",
    "    print(f\"Total errors: {total_errors}\")\n",
    "    if (total_processed + total_errors) > 0:\n",
    "        print(f\"Success rate: {total_processed/(total_processed + total_errors)*100:.1f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mes = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "face_mesh = mp_face_mes.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    H, W, _ = frame.shape\n",
    "    rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results_mesh = face_mesh.process(rgb_image)\n",
    "    mesh_points=np.array([np.multiply([p.x, p.y], [W, H]).astype(int) for p in results_mesh.multi_face_landmarks[0].landmark])\n",
    "    nose_tip = mesh_points[4]\n",
    "    forehead = mesh_points[151]\n",
    "    scale_factor = np.linalg.norm(forehead - nose_tip)\n",
    "    if np.isclose(scale_factor, 0):\n",
    "        scale_factor = 1e-6\n",
    "    return results_mesh, mesh_points, scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_grafos(results_mesh, mesh_points, scale_factor):\n",
    "    graph = nx.Graph()\n",
    "    # sabing all the nodes from mesh_points into the graph\n",
    "    for i in range(len(mesh_points)):\n",
    "        graph.add_node(i, pos=mesh_points[i])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(graph, mesh_points):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    nx.draw_networkx(graph, pos=mesh_points, node_size=10, node_color='black', edge_color='black', with_labels=False)\n",
    "    # flip the image upside down\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_adj(graph):\n",
    "    matrix_adj = nx.adjacency_matrix(graph)\n",
    "    sparce_matrix = scipy.sparse.csr_matrix(matrix_adj)\n",
    "    return sparce_matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_adjacency_matrix(adjacency_matrix, filename):\n",
    "    path_name = pathlib.Path(filename).parent.absolute()\n",
    "    emotion = path_name.name.split('_')[1]\n",
    "    path_name = path_name.parent.absolute()\n",
    "    path_name = path_name.joinpath(f'{emotion}_adj')\n",
    "    # separate the filename from the path\n",
    "    filename = pathlib.Path(filename).absolute()\n",
    "    # create te folder if it doesn't exist\n",
    "    path_name.mkdir(parents=True, exist_ok=True)\n",
    "    # save the npz file in the path_name\n",
    "    file_out = path_name.joinpath(f'{filename.name}.npz')\n",
    "    scipy.sparse.save_npz(file_out, adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_meshpoints(mesh_points, filename):\n",
    "    path_name = pathlib.Path(filename).parent.absolute()\n",
    "    emotion = path_name.name.split('_')[1]\n",
    "    path_name = path_name.parent.absolute()\n",
    "    path_name = path_name.joinpath(f'{emotion}_meshpoints')\n",
    "    # separete the filename from the path\n",
    "    filename = pathlib.Path(filename).absolute()\n",
    "    # create te folder if it doesn't exist\n",
    "    path_name.mkdir(parents=True, exist_ok=True)\n",
    "    # save the npz file in the path_name\n",
    "    file_out = path_name.joinpath(f'{filename.name}.json')\n",
    "    with open(file_out, 'w') as outfile:\n",
    "        json.dump(mesh_points.tolist(), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img, plot=False):\n",
    "    name = img.split('.')[0]\n",
    "    frame = cv2.imread(img)\n",
    "    results_mesh, mesh_points, scale_factor = preprocess_frame(frame)\n",
    "    graph = gera_grafos(results_mesh, mesh_points, scale_factor)\n",
    "    # adjacency_matrix = get_matrix_adj(graph)\n",
    "    # save_adjacency_matrix(adjacency_matrix, name)\n",
    "    save_meshpoints(mesh_points, name)\n",
    "    if plot:\n",
    "        plot_graph(graph, mesh_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the pipeline to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the actual path\n",
    "print(pathlib.Path().absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = pathlib.Path().absolute()\n",
    "path = current_path.parent\n",
    "\n",
    "angry_path = path / 'face_angry'\n",
    "disgusted_path = path / 'face_disgusted'\n",
    "happy_path = path / 'face_happy'\n",
    "neutral_path = path / 'face_neutral'\n",
    "sad_path = path / 'face_sad'\n",
    "surprised_path = path / 'face_surprised'\n",
    "\n",
    "path_list = [angry_path, disgusted_path, happy_path, neutral_path, sad_path, surprised_path]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion_path in path_list:\n",
    "    count = 0\n",
    "    p_c = 0\n",
    "    print(emotion_path)\n",
    "    emotion_files = os.listdir(emotion_path)\n",
    "    for img in emotion_files:\n",
    "        try:\n",
    "            path_img = emotion_path / img\n",
    "            print(path_img)\n",
    "            pipeline(str(path_img), plot=True)\n",
    "            if p_c == 10:\n",
    "                break\n",
    "            p_c += 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            count += 1\n",
    "            if count == 3:\n",
    "                break\n",
    "    print(count)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion_path in path_list:\n",
    "    count = 0\n",
    "    img_count =1\n",
    "    print(emotion_path)\n",
    "    emotion_files = os.listdir(emotion_path)\n",
    "    for img in emotion_files:\n",
    "        try:\n",
    "            path_img = emotion_path / img\n",
    "            pipeline(str(path_img), plot=True)\n",
    "            img_count += 1\n",
    "        except Exception as e:\n",
    "            #print(e)\n",
    "            count += 1\n",
    "            continue\n",
    "    print('erros',count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the amount of processed images\n",
    "for emotion_path in path_list:\n",
    "    print(len(os.listdir(emotion_path)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
