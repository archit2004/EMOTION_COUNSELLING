{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions.face_mesh_connections import FACEMESH_TESSELATION\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.sparse\n",
    "import pathlib, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path: d:\\hask\\GNN\n",
      "\n",
      "Processing emotion: face_angry\n",
      "Found 7978 image files\n",
      "Processing 1/7978: 0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\hask\\venv\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL SUMMARY ===\n",
      "Total images processed successfully: 47723\n",
      "Total errors: 3628\n",
      "Success rate: 92.9%\n"
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1, \n",
    "    refine_landmarks=False,  # Set to False to get 468 landmarks without iris\n",
    "    min_detection_confidence=0.5, \n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"\n",
    "    Process frame and extract facial landmarks\n",
    "    Returns None if no face is detected\n",
    "    \"\"\"\n",
    "    H, W, _ = frame.shape\n",
    "    rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results_mesh = face_mesh.process(rgb_image)\n",
    "    \n",
    "    # Check if face landmarks were detected\n",
    "    if not results_mesh.multi_face_landmarks:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Extract mesh points\n",
    "    mesh_points = np.array([\n",
    "        np.multiply([p.x, p.y], [W, H]).astype(int) \n",
    "        for p in results_mesh.multi_face_landmarks[0].landmark\n",
    "    ])\n",
    "    \n",
    "    # Calculate scale factor using nose tip and forehead\n",
    "    nose_tip = mesh_points[4]\n",
    "    forehead = mesh_points[151]\n",
    "    scale_factor = np.linalg.norm(forehead - nose_tip)\n",
    "    \n",
    "    if np.isclose(scale_factor, 0):\n",
    "        scale_factor = 1e-6\n",
    "        \n",
    "    return results_mesh, mesh_points, scale_factor\n",
    "\n",
    "def gera_grafos(results_mesh, mesh_points, scale_factor):\n",
    "    \"\"\"Generate graph from mesh points\"\"\"\n",
    "    graph = nx.Graph()\n",
    "    \n",
    "    # Add all nodes from mesh_points to the graph\n",
    "    for i in range(len(mesh_points)):\n",
    "        graph.add_node(i, pos=mesh_points[i])\n",
    "    \n",
    "    # Add edges based on MediaPipe face mesh connections\n",
    "    for connection in FACEMESH_TESSELATION:\n",
    "        graph.add_edge(connection[0], connection[1])\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def plot_graph(graph, mesh_points):\n",
    "    \"\"\"Plot the facial mesh graph\"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    pos_dict = {i: mesh_points[i] for i in range(len(mesh_points))}\n",
    "    nx.draw_networkx(\n",
    "        graph, \n",
    "        pos=pos_dict, \n",
    "        node_size=10, \n",
    "        node_color='black', \n",
    "        edge_color='gray', \n",
    "        with_labels=False,\n",
    "        width=0.5\n",
    "    )\n",
    "    # Flip the image upside down to match face orientation\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"Facial Mesh Graph\")\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "def get_matrix_adj(graph):\n",
    "    \"\"\"Get adjacency matrix from graph\"\"\"\n",
    "    matrix_adj = nx.adjacency_matrix(graph)\n",
    "    sparse_matrix = scipy.sparse.csr_matrix(matrix_adj)\n",
    "    return sparse_matrix\n",
    "\n",
    "def save_adjacency_matrix(adjacency_matrix, filename):\n",
    "    \"\"\"Save adjacency matrix to file\"\"\"\n",
    "    path_name = pathlib.Path(filename).parent.absolute()\n",
    "    emotion = path_name.name.split('_')[1]\n",
    "    path_name = path_name.parent.absolute()\n",
    "    path_name = path_name.joinpath(f'{emotion}_adj')\n",
    "    \n",
    "    filename = pathlib.Path(filename).absolute()\n",
    "    path_name.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    file_out = path_name.joinpath(f'{filename.stem}.npz')\n",
    "    scipy.sparse.save_npz(file_out, adjacency_matrix)\n",
    "\n",
    "def save_meshpoints(mesh_points, filename):\n",
    "    \"\"\"Save mesh points to JSON file\"\"\"\n",
    "    path_name = pathlib.Path(filename).parent.absolute()\n",
    "    emotion = path_name.name.split('_')[1]\n",
    "    path_name = path_name.parent.absolute()\n",
    "    path_name = path_name.joinpath(f'{emotion}_meshpoints')\n",
    "    \n",
    "    filename = pathlib.Path(filename).absolute()\n",
    "    path_name.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    file_out = path_name.joinpath(f'{filename.stem}.json')\n",
    "    with open(file_out, 'w') as outfile:\n",
    "        json.dump(mesh_points.tolist(), outfile)\n",
    "\n",
    "def pipeline(img_path, plot=False, verbose=False):\n",
    "    \"\"\"Main processing pipeline\"\"\"\n",
    "    try:\n",
    "        # Read image\n",
    "        frame = cv2.imread(img_path)\n",
    "        if frame is None:\n",
    "            if verbose:\n",
    "                print(f\"Could not read image: {img_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Preprocess frame\n",
    "        results_mesh, mesh_points, scale_factor = preprocess_frame(frame)\n",
    "        \n",
    "        if results_mesh is None:\n",
    "            if verbose:\n",
    "                print(f\"No face detected in: {img_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Generate graph\n",
    "        graph = gera_grafos(results_mesh, mesh_points, scale_factor)\n",
    "        \n",
    "        # Save data\n",
    "        name = pathlib.Path(img_path).stem\n",
    "        adjacency_matrix = get_matrix_adj(graph)\n",
    "        save_adjacency_matrix(adjacency_matrix, img_path)\n",
    "        save_meshpoints(mesh_points, img_path)\n",
    "        \n",
    "        # Plot if requested\n",
    "        if plot:\n",
    "            plot_graph(graph, mesh_points)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error processing {img_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def process_dataset(verbose=False, show_progress=True):\n",
    "    \"\"\"Process the entire dataset - ALL images in ALL emotion folders\"\"\"\n",
    "    print(\"Current path:\", pathlib.Path().absolute())\n",
    "    current_path = pathlib.Path().absolute()\n",
    "    parent_path = current_path.parent\n",
    "    \n",
    "    # Define emotion paths\n",
    "    emotion_folders = [\n",
    "        'face_angry', 'face_disgusted', 'face_happy', \n",
    "        'face_neutral', 'face_sad', 'face_surprised'\n",
    "    ]\n",
    "    \n",
    "    path_list = [parent_path / folder for folder in emotion_folders]\n",
    "    \n",
    "    total_processed = 0\n",
    "    total_errors = 0\n",
    "    \n",
    "    for emotion_path in path_list:\n",
    "        if not emotion_path.exists():\n",
    "            print(f\"Path does not exist: {emotion_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing emotion: {emotion_path.name}\")\n",
    "        \n",
    "        error_count = 0\n",
    "        img_count = 0\n",
    "        \n",
    "        try:\n",
    "            emotion_files = os.listdir(emotion_path)\n",
    "            image_files = [f for f in emotion_files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "            \n",
    "            print(f\"Found {len(image_files)} image files\")\n",
    "            \n",
    "            for img in image_files:\n",
    "                try:\n",
    "                    path_img = emotion_path / img\n",
    "                    \n",
    "                    # Show progress every 100 images (or based on show_progress)\n",
    "                    if show_progress and (img_count % 100 == 0 or img_count < 10):\n",
    "                        print(f\"Processing {img_count+1}/{len(image_files)}: {img}\")\n",
    "                    \n",
    "                    success = pipeline(str(path_img), plot=False, verbose=verbose)\n",
    "                    \n",
    "                    if success:\n",
    "                        total_processed += 1\n",
    "                        if verbose and img_count < 5:  # Only show first few if verbose\n",
    "                            print(f\"✅ Successfully processed: {img}\")\n",
    "                    else:\n",
    "                        error_count += 1\n",
    "                        total_errors += 1\n",
    "                        if verbose:\n",
    "                            print(f\"❌ Failed to process: {img}\")\n",
    "                    \n",
    "                    img_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if verbose:\n",
    "                        print(f\"❌ Error processing {img}: {str(e)}\")\n",
    "                    error_count += 1\n",
    "                    total_errors += 1\n",
    "                    continue\n",
    "            \n",
    "            print(f\"Completed {emotion_path.name}: {img_count} total, {error_count} errors\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing folder {emotion_path}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\n=== FINAL SUMMARY ===\")\n",
    "    print(f\"Total images processed successfully: {total_processed}\")\n",
    "    print(f\"Total errors: {total_errors}\")\n",
    "    if (total_processed + total_errors) > 0:\n",
    "        print(f\"Success rate: {total_processed/(total_processed + total_errors)*100:.1f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mes = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "face_mesh = mp_face_mes.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    H, W, _ = frame.shape\n",
    "    rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results_mesh = face_mesh.process(rgb_image)\n",
    "    mesh_points=np.array([np.multiply([p.x, p.y], [W, H]).astype(int) for p in results_mesh.multi_face_landmarks[0].landmark])\n",
    "    nose_tip = mesh_points[4]\n",
    "    forehead = mesh_points[151]\n",
    "    scale_factor = np.linalg.norm(forehead - nose_tip)\n",
    "    if np.isclose(scale_factor, 0):\n",
    "        scale_factor = 1e-6\n",
    "    return results_mesh, mesh_points, scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_grafos(results_mesh, mesh_points, scale_factor):\n",
    "    graph = nx.Graph()\n",
    "    # sabing all the nodes from mesh_points into the graph\n",
    "    for i in range(len(mesh_points)):\n",
    "        graph.add_node(i, pos=mesh_points[i])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(graph, mesh_points):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    nx.draw_networkx(graph, pos=mesh_points, node_size=10, node_color='black', edge_color='black', with_labels=False)\n",
    "    # flip the image upside down\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_adj(graph):\n",
    "    matrix_adj = nx.adjacency_matrix(graph)\n",
    "    sparce_matrix = scipy.sparse.csr_matrix(matrix_adj)\n",
    "    return sparce_matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_adjacency_matrix(adjacency_matrix, filename):\n",
    "    path_name = pathlib.Path(filename).parent.absolute()\n",
    "    emotion = path_name.name.split('_')[1]\n",
    "    path_name = path_name.parent.absolute()\n",
    "    path_name = path_name.joinpath(f'{emotion}_adj')\n",
    "    # separate the filename from the path\n",
    "    filename = pathlib.Path(filename).absolute()\n",
    "    # create te folder if it doesn't exist\n",
    "    path_name.mkdir(parents=True, exist_ok=True)\n",
    "    # save the npz file in the path_name\n",
    "    file_out = path_name.joinpath(f'{filename.name}.npz')\n",
    "    scipy.sparse.save_npz(file_out, adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_meshpoints(mesh_points, filename):\n",
    "    path_name = pathlib.Path(filename).parent.absolute()\n",
    "    emotion = path_name.name.split('_')[1]\n",
    "    path_name = path_name.parent.absolute()\n",
    "    path_name = path_name.joinpath(f'{emotion}_meshpoints')\n",
    "    # separete the filename from the path\n",
    "    filename = pathlib.Path(filename).absolute()\n",
    "    # create te folder if it doesn't exist\n",
    "    path_name.mkdir(parents=True, exist_ok=True)\n",
    "    # save the npz file in the path_name\n",
    "    file_out = path_name.joinpath(f'{filename.name}.json')\n",
    "    with open(file_out, 'w') as outfile:\n",
    "        json.dump(mesh_points.tolist(), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img, plot=False):\n",
    "    name = img.split('.')[0]\n",
    "    frame = cv2.imread(img)\n",
    "    results_mesh, mesh_points, scale_factor = preprocess_frame(frame)\n",
    "    graph = gera_grafos(results_mesh, mesh_points, scale_factor)\n",
    "    # adjacency_matrix = get_matrix_adj(graph)\n",
    "    # save_adjacency_matrix(adjacency_matrix, name)\n",
    "    save_meshpoints(mesh_points, name)\n",
    "    if plot:\n",
    "        plot_graph(graph, mesh_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the pipeline to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the actual path\n",
    "print(pathlib.Path().absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = pathlib.Path().absolute()\n",
    "path = current_path.parent\n",
    "\n",
    "angry_path = path / 'face_angry'\n",
    "disgusted_path = path / 'face_disgusted'\n",
    "happy_path = path / 'face_happy'\n",
    "neutral_path = path / 'face_neutral'\n",
    "sad_path = path / 'face_sad'\n",
    "surprised_path = path / 'face_surprised'\n",
    "\n",
    "path_list = [angry_path, disgusted_path, happy_path, neutral_path, sad_path, surprised_path]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion_path in path_list:\n",
    "    count = 0\n",
    "    p_c = 0\n",
    "    print(emotion_path)\n",
    "    emotion_files = os.listdir(emotion_path)\n",
    "    for img in emotion_files:\n",
    "        try:\n",
    "            path_img = emotion_path / img\n",
    "            print(path_img)\n",
    "            pipeline(str(path_img), plot=True)\n",
    "            if p_c == 10:\n",
    "                break\n",
    "            p_c += 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            count += 1\n",
    "            if count == 3:\n",
    "                break\n",
    "    print(count)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion_path in path_list:\n",
    "    count = 0\n",
    "    img_count =1\n",
    "    print(emotion_path)\n",
    "    emotion_files = os.listdir(emotion_path)\n",
    "    for img in emotion_files:\n",
    "        try:\n",
    "            path_img = emotion_path / img\n",
    "            pipeline(str(path_img), plot=True)\n",
    "            img_count += 1\n",
    "        except Exception as e:\n",
    "            #print(e)\n",
    "            count += 1\n",
    "            continue\n",
    "    print('erros',count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the amount of processed images\n",
    "for emotion_path in path_list:\n",
    "    print(len(os.listdir(emotion_path)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
